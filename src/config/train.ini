
[COMMON]
seed =  88

# 1. set dataset, model
# dataset: funsd, funsdplus, cord, rvl, sroie, docvqa_ocr, findoc_ner, findoc_cat
dataset_name = findoc_vqa

# tbox or bbox
bbox_type = tbox
# layoutlmv1, layoutlmv2, layoutlmv3 spatial_lm, roberta, layoutlmv3_disent, bert
network_type = layoutlmv3
# output_dir = layoutlmv3-cord

# 2. {mlm, token-classifier, sequence-classifier, docvqa, docbqa}
task_type = docvqa

# === if you use all, set -1, otherwise set a number that you want to test
test_small_samp = 100

# when inference set True, default by False
inference_only = False
# do not use {binary-label, multi-label, regression }, because you need specific task preparation info.
# 2.2 task usage
# graph_feature = True
# graph_vect_path = /home/ubuntu/python_projects/DocGraph4LM/src/tmp_dir/graphsage_docvqa4g_522066/
# BERT sequence can be sub-word sequence;  

# 3. set hyper parameters
batch_size = 4
epochs = 2
lr = 0.0001
patience = 30
dropout = 0.1
max_seq_len = 512

spatial_attention = False

# hidden_size = 768
# hidden_dim = 100
# hidden_dim_1 = 64
# hidden_dim_2 = 32

# 4. continue train
# continue_train = True
# continue_with_model = /home/ubuntu/air/vrdu/models/csmodel_rvlcdip_initial/
layoutlm_dir = /home/ubuntu/air/vrdu/models/layoutlmv3.base
# layoutlm_dir = /home/ubuntu/air/vrdu/models/layoutlmv3.base
checkpoint_path = /home/ubuntu/air/vrdu/output/pretrain_rvl/disentlm_a_false/checkpoint-44000

# checkpoint_path = /home/ubuntu/python_projects/Spatial-LM/src/tmp_dir
# checkpoint_path = /home/ubuntu/air/vrdu/output/pretrain_rvl/test_base/checkpoint-22485
# checkpoint_path = /home/ubuntu/python_projects/Spatial-LM/src/tmp_dir/checkpoint-200
# save_model = False
# {no, epoch, steps}, usually use no or epoch for training
save_strategy = no
checkpoint_save_path = /home/ubuntu/air/vrdu/models/b2m_base_rvl/

# other less common parameters 
embedding_trainable = True

# rvl_cdip_ds = /home/ubuntu/air/vrdu/datasets/rvl_HF_datasets/weighted_rvl1_dataset.hf
bert_dir = /home/ubuntu/air/vrdu/models/bert.base.uncased
roberta_dir = /home/ubuntu/air/vrdu/models/roberta.base.squad

# /home/ubuntu/air/vrdu/datasets/no_is_key_no_rare

# layoutlm_large = /home/ubuntu/air/vrdu/models/layoutlmv1.large
# layoutlm_large = /home/ubuntu/air/vrdu/models/roberta.base.squad
# layoutlm_dir = /home/ubuntu/resources/layoutlmv3.base
# layoutlm_dir = /home/ubuntu/air/vrdu/models/layoutlmv3.docvqa
# layoutlm_dir = /home/ubuntu/air/vrdu/models/layoutlmv3.large

funsd_train = /home/ubuntu/air/vrdu/datasets/FUNSD/training_data/
funsd_test = /home/ubuntu/air/vrdu/datasets/FUNSD/testing_data/

funsdplus_train = /home/ubuntu/air/vrdu/datasets/funsd_plus/train_data
funsdplus_val = /home/ubuntu/air/vrdu/datasets/funsd_plus/val_data
funsdplus_test = /home/ubuntu/air/vrdu/datasets/funsd_plus/test_data

cord_train = /home/ubuntu/air/vrdu/datasets/CORD/train/
cord_test = /home/ubuntu/air/vrdu/datasets/CORD/test/

rvl_train = /home/ubuntu/air/vrdu/datasets/rvl_HF_datasets/full_rvl_train0_dataset.hf
rvl_test = /home/ubuntu/air/vrdu/datasets/rvl_HF_datasets/full_rvl_test2_dataset.hf

sorie_train = /home/ubuntu/air/vrdu/datasets/sorie2019/sorie_train.hf
sorie_test = /home/ubuntu/air/vrdu/datasets/sorie2019/sorie_test.hf

docvqa_pickles = /home/ubuntu/air/vrdu/datasets/docvqa/pickles/
filter_no_answer = True

# findoc_dir = /home/ubuntu/air/vrdu/datasets/findoc_v1
findoc_dir = /home/ubuntu/air/vrdu/datasets/no_is_key_no_rare
# 88.49 /50; prec 87.37, rec 89.65

# base on funsd: 89.10, rec:89.5, prec: 88.52
# base on funsd + sp: 

# base on cord: 96.37, rec: 96.48, prec: 96.27

# base on sorie: 95.13, rec = 95.50, prec = 94.77

# 'eval_precision': 0.9590864278672363, 'eval_recall': 0.9679933665008292, 'eval_f1': 0.9635193133047211, 'eval_accuracy': 0.9890808220905308,

# train: 39289
# train docvqa: 36504

# train rvl, 356725, test on 
# params: 357070969
