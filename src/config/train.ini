
[COMMON]
seed =  88


# 1. set dataset, model
# dataset: funsd, cord
dataset_name = cord
# docvqa to use: {1,2,3}
train_part = 1
# layoutlm, spatial_lm, roberta, graph_roberta
network_type = spatial_lm
# output_dir = layoutlmv3-cord

# 2. {mlm, token-classifier}
task_type = token-classifier

num_cpu = 64

# do not use {binary-label, multi-label, regression }, because you need specific task preparation info.
# 2.2 task usage
# graph_feature = True
# graph_vect_path = /home/ubuntu/python_projects/DocGraph4LM/src/tmp_dir/graphsage_docvqa4g_522066/
# BERT sequence can be sub-word sequence;  

# 3. set hyper parameters
batch_size = 3
epochs = 12
lr = 0.00005
patience = 20
dropout = 0.1
max_seq_len = 512

# hidden_size = 768
# hidden_dim = 100
# hidden_dim_1 = 64
# hidden_dim_2 = 32

# 4. continue train
# continue_train = True
# continue_with_model = /home/ubuntu/air/vrdu/models/csmodel_rvlcdip_initial/

layoutlm_dir = /home/ubuntu/air/vrdu/models/layoutlmv3.base
checkpoint_path = /home/ubuntu/python_projects/Spatial-LM/src/trained_path/base
# checkpoint_path = /home/ubuntu/python_projects/Spatial-LM/src/tmp_dir/checkpoint-200

# other less common parameters 
embedding_trainable = True

# rvl_cdip_ds = /home/ubuntu/air/vrdu/datasets/rvl_HF_datasets/weighted_rvl1_dataset.hf


# layoutlm_large = /home/ubuntu/air/vrdu/models/layoutlmv1.large
# layoutlm_large = /home/ubuntu/air/vrdu/models/roberta.base.squad
# layoutlm_dir = /home/ubuntu/resources/layoutlmv3.base
# layoutlm_dir = /home/ubuntu/air/vrdu/models/layoutlmv3.docvqa
# layoutlm_dir = /home/ubuntu/air/vrdu/models/layoutlmv3.large

funsd_train = /home/ubuntu/air/vrdu/datasets/FUNSD/training_data/
funsd_test = /home/ubuntu/air/vrdu/datasets/FUNSD/testing_data/

cord_train = /home/ubuntu/air/vrdu/datasets/CORD/train/
cord_test = /home/ubuntu/air/vrdu/datasets/CORD/test/


# 88.49 /50; prec 87.37, rec 89.65

# base on funsd: 89.10, rec:89.5, prec: 88.52

